If a large language model were released to the public without any censorship whatsoever what kind of behavior would it have? Would it have an inherent sense of right and wrong? If the user were mentally ill and contemplating self harm, would it be able to advise them to get professional help and not to harm themselves? Or do these basic guardrails have to be deliberately built in every time?